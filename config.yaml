# Configuration for CLI Chat App
model_name: "gemma3n-clean"  # Clean template variant of gemma3n:e4b
model_provider: "ollama"
base_url: "http://localhost:11434"
keep_alive: -1  # Keep model loaded in memory
streaming: true
history_turns: 4  # Number of conversation turns to keep in memory
timeout: 30  # Request timeout in seconds

# System prompt - explicitly forbids chain-of-thought
system_prompt: |
  You are a concise assistant. Reply briefly and helpfully.
  Do NOT include chain-of-thought, reasoning steps, or <think> blocks.
  Only provide final answers directly.

# Model parameters
temperature: 0.7
max_tokens: 1024